{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = torchvision.datasets.MNIST(root='../data', train=True, transform=transform, download=True)\n",
    "\n",
    "train_val_data, test_data = train_test_split(full_data, test_size=0.2, shuffle=True)\n",
    "\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNet(nn.Module):\n",
    "    def __init__(self, n_nodes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, n_nodes)\n",
    "        self.bn1 = nn.BatchNorm1d(n_nodes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(n_nodes, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict()\n",
    "            self.counter = 0\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 32\n",
    "net = ShallowNet(n_nodes).to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Rprop(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(running_loss, train_loader):\n",
    "    for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs = inputs.view(-1, 28*28)\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "        \n",
    "            running_loss += loss.item()\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            images = images.view(-1, 28*28)\n",
    "            outputs = net(images)\n",
    "            _, prediction = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            loss = loss_function(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "\n",
    "            correct += (prediction == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training epoch 1...\n",
      "Loss: 0.9796\n",
      "Validation Accuracy: 90.10%\n",
      "Training epoch 2...\n",
      "Loss: 1.1845\n",
      "Validation Accuracy: 90.04%\n",
      "Training epoch 3...\n",
      "Loss: 1.1527\n",
      "Validation Accuracy: 90.09%\n",
      "Training epoch 4...\n",
      "Loss: 1.1106\n",
      "Validation Accuracy: 90.13%\n",
      "Training epoch 5...\n",
      "Loss: 1.0809\n",
      "Validation Accuracy: 90.16%\n",
      "Training epoch 6...\n",
      "Loss: 1.0979\n",
      "Validation Accuracy: 90.23%\n",
      "Training epoch 7...\n",
      "Loss: 1.0934\n",
      "Validation Accuracy: 90.25%\n",
      "Training epoch 8...\n",
      "Loss: 1.0456\n",
      "Validation Accuracy: 90.26%\n",
      "Training epoch 9...\n",
      "Loss: 1.0340\n",
      "Validation Accuracy: 90.36%\n",
      "Training epoch 10...\n",
      "Loss: 1.0184\n",
      "Validation Accuracy: 90.37%\n",
      "Training epoch 11...\n",
      "Loss: 0.9975\n",
      "Validation Accuracy: 90.41%\n",
      "Training epoch 12...\n",
      "Loss: 0.9914\n",
      "Validation Accuracy: 90.45%\n",
      "Training epoch 13...\n",
      "Loss: 0.9813\n",
      "Validation Accuracy: 90.49%\n",
      "Training epoch 14...\n",
      "Loss: 0.9570\n",
      "Validation Accuracy: 90.55%\n",
      "Training epoch 15...\n",
      "Loss: 0.9581\n",
      "Validation Accuracy: 90.61%\n",
      "Training epoch 16...\n",
      "Loss: 0.9806\n",
      "Validation Accuracy: 90.65%\n",
      "Training epoch 17...\n",
      "Loss: 0.9958\n",
      "Validation Accuracy: 90.68%\n",
      "Training epoch 18...\n",
      "Loss: 0.9698\n",
      "Validation Accuracy: 90.67%\n",
      "Training epoch 19...\n",
      "Loss: 0.9579\n",
      "Validation Accuracy: 90.70%\n",
      "Training epoch 20...\n",
      "Loss: 0.9624\n",
      "Validation Accuracy: 90.71%\n",
      "Best accuracy for fold 1 was: 90.71%\n",
      "Fold 2/5\n",
      "Training epoch 1...\n",
      "Loss: 0.8913\n",
      "Validation Accuracy: 90.60%\n",
      "Training epoch 2...\n",
      "Loss: 0.8913\n",
      "Validation Accuracy: 90.56%\n",
      "Training epoch 3...\n",
      "Loss: 0.8494\n",
      "Validation Accuracy: 90.55%\n",
      "Training epoch 4...\n",
      "Loss: 0.8557\n",
      "Validation Accuracy: 90.58%\n",
      "Training epoch 5...\n",
      "Loss: 0.8529\n",
      "Validation Accuracy: 90.63%\n",
      "Training epoch 6...\n",
      "Loss: 0.8342\n",
      "Validation Accuracy: 90.67%\n",
      "Training epoch 7...\n",
      "Loss: 0.8346\n",
      "Validation Accuracy: 90.67%\n",
      "Training epoch 8...\n",
      "Loss: 0.8275\n",
      "Validation Accuracy: 90.71%\n",
      "Training epoch 9...\n",
      "Loss: 0.8481\n",
      "Validation Accuracy: 90.72%\n",
      "Training epoch 10...\n",
      "Loss: 0.8266\n",
      "Validation Accuracy: 90.72%\n",
      "Training epoch 11...\n",
      "Loss: 0.7999\n",
      "Validation Accuracy: 90.84%\n",
      "Training epoch 12...\n",
      "Loss: 0.8001\n",
      "Validation Accuracy: 90.80%\n",
      "Training epoch 13...\n",
      "Loss: 0.8046\n",
      "Validation Accuracy: 90.85%\n",
      "Training epoch 14...\n",
      "Loss: 0.8361\n",
      "Validation Accuracy: 90.83%\n",
      "Training epoch 15...\n",
      "Loss: 0.9214\n",
      "Validation Accuracy: 90.88%\n",
      "Training epoch 16...\n",
      "Loss: 0.9186\n",
      "Validation Accuracy: 90.83%\n",
      "Training epoch 17...\n",
      "Loss: 0.9214\n",
      "Validation Accuracy: 90.90%\n",
      "Training epoch 18...\n",
      "Loss: 0.9279\n",
      "Validation Accuracy: 90.88%\n",
      "Training epoch 19...\n",
      "Loss: 0.9237\n",
      "Validation Accuracy: 90.91%\n",
      "Training epoch 20...\n",
      "Loss: 0.9376\n",
      "Validation Accuracy: 90.88%\n",
      "Best accuracy for fold 2 was: 90.88%\n",
      "Fold 3/5\n",
      "Training epoch 1...\n",
      "Loss: 0.9681\n",
      "Validation Accuracy: 91.20%\n",
      "Training epoch 2...\n",
      "Loss: 0.9730\n",
      "Validation Accuracy: 91.21%\n",
      "Training epoch 3...\n",
      "Loss: 0.9916\n",
      "Validation Accuracy: 91.23%\n",
      "Training epoch 4...\n",
      "Loss: 0.9905\n",
      "Validation Accuracy: 91.22%\n",
      "Training epoch 5...\n",
      "Loss: 0.9881\n",
      "Validation Accuracy: 91.28%\n",
      "Training epoch 6...\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "all_accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(full_data)))):\n",
    "    print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "    train_subset = torch.utils.data.Subset(full_data, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(full_data, val_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=1000, shuffle=True, num_workers=2)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, delta=0.01)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        print(f'Training epoch {epoch+1}...')\n",
    "        \n",
    "        running_loss = train_loop(0.0, train_loader)\n",
    "        val_loss, accuracy = test_loop(val_loader)\n",
    "\n",
    "        print(f'Loss: {running_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        early_stopping(val_loss, net)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break   \n",
    "\n",
    "        if (best_accuracy < accuracy):\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    print(f'Best accuracy for fold {fold+1} was: {accuracy:.2f}%')\n",
    "\n",
    "    early_stopping.load_best_model(net)\n",
    "    all_accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(all_accuracies)\n",
    "std_accuracy = np.std(all_accuracies)\n",
    "\n",
    "print(f'Cross-Validation Accuracy: {average_accuracy:.2f}% Â± {std_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = test_loop(test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
